<!-- v ieee cookie banner v -->
 <script src="https://cmp.osano.com/AzyzptTmRlqVd2LRf/fa3a4368-ed96-4d89-a5c5-260c44be73cf/osano.js"></script>
 <link rel="stylesheet" href="https://cookie-consent.ieee.org/ieee-cookie-banner.css" type="text/css"/>
 <!-- ^ ieee cookie banner ^ -->

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<HTML xmlns="http://www.w3.org/1999/xhtml">
    <HEAD>
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <TITLE>Third Workshop on AI and AR/VR for Exergaming (AIVR4Exergame 2026) - co-located with IEEE AIxVR 2026 in Osaka, Japan</TITLE>
        <LINK rel="StyleSheet" href="./webstyle.css" type="text/css" media="all">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
        <script src="jquery-3.2.1.js"></script>
    </HEAD>
    <BODY style="margin: 0px;">
        <div class="header">
            <div class="header-bar">
                <div class="navTable">
                    <div class="navRow" id="myNavRow">                     
                                                
						<div style="display:table-cell;"  class="button" data-path="schedule">SCHEDULE</div>
						<div style="display:table-cell;" class="button" data-path="invitedtalks">INVITED TALKS</div>
						<div style="display:table-cell;" class="button" data-path="theabout">ABOUT</div>
                        <div style="display:table-cell;" class="button" data-path="theorg">ORGANIZERS</div>
                    </div>
                </div>
            </div>
        </div>
        
        
        <div id="container" class="content">
            <div id="thetop" class="topBackground backBanner">
                    <!--<img src = "./images/back.jpg"/>-->
            </div>
            <div style="background-color: #CCCCCC; z-index: 10; position: fixed; left: 10px; padding: 10px; border-radius: 10px;" class="button" data-path="thetop">
                Top
            </div>
            
			<div id="schedule" class="projectItem">
				<div class="shrunkLeft">
				<p><h1>Third Workshop on AI and AR/VR for Exergaming (AIVR4Exergame)</h1></p>

                <p>The workshop will be held <b>in-person (with remote options)</b> at the Osaka University Toyonaka Campus, in Toyonaka, Osaka, Japan, and is co-located with <a href="https://aivr.science.uu.nl/2026/" target="_blank">IEEE AIxVR 2026</a>.</p>
				
				<h3>SCHEDULE</h3>
				<p>All times are local to Osaka</p>
					<ul>
						<li>9:00am to 9:15am: Opening Remarks by Workshop Organizers Dr. Sean Banerjee and Dr. Natasha Banerjee (<a href="https://tars-home.github.io/"target="_blank">Terascale All-sensing Research Studio</a> at Wright State University, USA)</li>
						<li>9:15am to 10:15am: Invited talk by Dr. Anat Lubetzky, Associate Professor, Department of Physical Therapy, New York University, United States: "Virtual Reality Applications in Balance and Rehabilitation Sciences"</li>
						<li>10:15am to 10:25am: Paper Session: Enhancing Intrinsic Motivation Through Difficulty Adaptation Based on Personality in a VR Exergame: Yusuke Goutsu and Tetsunari Inamura</li>
						<li>10:25am to 10:35am: Paper Session: Card. I/O: Exercise Data-driven AI Generative Content in Immersive Exertion Interaction for Personal Informatics Reflection: Kuan Ning Chang, Yu-Hin Chan, Tse-Yu Pan, Chien-Hsing Chou and Ping-Hsuan Han</li>
						<li>10:35am to 10:45am: Paper Session: Kinesthetic Drills for Enhancing Children's Engagement in Four Basic Arithmetic: Itsuki Arita and Nobuyuki Umezu</li>
						<li>10:45am to 11:00am: Coffee Break</li>
						<li>11:00am to 12:00pm: Invited talk by Dr. Tetsunari Inamura, Professor, Brain Science Institute Advanced Intelligence & Robotics Research Center, Tamagawa University, Japan: "Self-Efficacy–Driven AR/VR Exergaming for Assistive and Rehabilitation Technologies"</li>
					</ul>
					<ul>
						<li>12:00pm to 1:30pm: Lunch</li>
					</ul>
					<ul>
						<li>2:30pm to 2:40pm: Paper Session: Breath-Controlled Virtual Reality using Thermal Thin-Medium Imaging: Breawn Schoun and Min-Hyung Choi</li>
						<li>2:40pm to 2:50pm: Paper Session: Challenges in the use of virtual reality by older adults: Victoria Silva, Marcio Catapan, Camila Tempesta and Lucas Gregory</li>
						<li>2:50pm to 3:00pm: Paper Session</li>
						<li>3:00pm to 3:30pm: Coffee Break</li>
						<li>3:30pm to 4:30pm: Invited talk by Dr. Annie Wan, Associate Professor, Faculty of Creative and Critical Studies, University of British Columbia (Okanagan Campus), Canada: "V CARE: A Virtual Reality (VR) Artificial Intelligence (AI) Assisted Training Tool for Alzheimer’s Caregivers 2.0"</li>
					</ul>								
				</div>
			</div>
			
            <div id="invitedtalks" class="projectItem2">
				<div class="shrunkLeft">
				<h2>INVITED TALKS</h2>
				<p>The 2026 edition of the Workshop on AI and AR/VR for Exergaming (AIVR4Exergame) held in conjunction with the 2026 IEEE International Conference on Artificial Intelligence & extended and Virtual Reality (AIxVR) will host as invited speakers:</p>

				<p><h3>Invited Talk: Dr. Anat Lubetzky, Associate Professor, Department of Physical Therapy, New York University, United States</h3></p>
				<p><b>Title: Virtual Reality Applications in Balance and Rehabilitation Sciences</b></p>
				<p><img src="images/anat.jpg">With recent advances in virtual reality technology, head-mounted displays (HMDs) are currently affordable and accessible. Low latency and accurate head tracking as well as the ability to systematically manipulate the environment complexity tracking provide a unique opportunity to study the mechanisms of balance disorders, especially sensory integration. Paradigms combining HMD and brain imaging also allow for better understanding of how the brain controls balance. HMD’s portability enables research outside the lab in clinics and the community at large (e.g., schools).</p>
				<p>Dr. Anat Lubetzky, PT, PhD, CSCS, is an Associate Professor at New York University, Department of Physical Therapy, and the Director of NYU Steinhardt’s PhD Program in Rehabilitation Sciences. Her work has been funded by the NIH and the Hearing Health Foundation. In this talk Dr. Lubetzky will share her lab’s journey through multiple research designs: Mechanistic studies to better understanding study sensory integration for postural control and how the brain controls balance; Clinical studies to develop and validate instrumented assessments of balance, and Intervention studies using HMD for balance rehabilitation and exergaming to reduce stress in high-schoolers.</p>

				<p><h3>Invited Talk: Dr. Tetsunari Inamura, Professor, Brain Science Institute Advanced Intelligence & Robotics Research Center, Tamagawa University, Japan</h3></p>
				<p><b>Title:  Self-Efficacy–Driven AR/VR Exergaming for Assistive and Rehabilitation Technologies</b></p>
				<p><img src="images/inamura.jpg">In healthcare and rehabilitation contexts, AR/VR exergaming has gained attention as an engaging way to promote physical recovery. Yet engagement alone is insufficient for sustained improvement—users must also develop confidence in their own abilities. This talk introduces a self-efficacy–driven approach to AR/VR exergaming that integrates AI, VR illusion systems, and assistive robotics. The proposed framework emphasizes gradual mastery, adaptive feedback, and reflective interaction, enabling users to experience success and regain a sense of control over their bodies and actions. By showcasing examples of VR-based exergames and assistive scenarios, we discuss how such systems can support both physical training and mental well-being. The talk concludes by outlining future directions for AI-powered exergaming as a core component of human-centered assistive and rehabilitation technologies.</p>
				<p>Dr. Tetsunari Inamura is a Professor and Head of the Advanced Intelligence & Robotics Research Center at Tamagawa University, Japan.
In 2010, he developed SIGVerse, an open platform for simulating human–robot interaction (HRI), which has been used more than 5,000 times worldwide. He has organized the RoboCup@Home Simulation League for over a decade and currently serves as Chair of the RoboCup Japan Committee for the @Home League. He also serves as Co-Chair of the IEEE RAS Technical Committee on Cognitive Robotics and as a member of the Steering Committee of IEEE Transactions on Cognitive and Developmental Systems. He is currently Vice President and a Fellow of the Robotics Society of Japan (RSJ). His research interests include learning from demonstration, symbol emergence, assessment of Human-Robot Interaction(HRI) quality, VR-based HRI systems, and affective computing for assistive robotics.</p>
					
				<p><h3>Invited Talk: Dr. Annie Wan, Associate Professor, Faculty of Creative and Critical Studies, University of British Columbia (Okanagan Campus), Canada</h3></p>
				<p><b>Title: V CARE: A Virtual Reality (VR) Artificial Intelligence (AI) Assisted Training Tool for Alzheimer’s Caregivers 2.0</b></p>
				<p><img src="images/annie.jpg">Around 800,000 Canadians are currently coping with Alzheimer's or a similar form of dementia, placing significant physical and emotional strain on their caregivers. We positioned AI and VR training as a crucial resource in alleviating caregiver stress, boosting confidence in their roles, and fostering a more supportive societal attitude towards Alzheimer's. Our research also aims to enhance awareness and support for Alzheimer's caregivers, and to disseminate this support through three training workshops in Greater Vancouver in 2024. By advocating for and contributing to positive changes in healthcare practices, this project seeks to empower caregivers and promote inclusive attitudes toward Alzheimer's within society.</p>
				<p>Dr. Annie Wan is currently an Associate Professor at Faculty of Creative and Critical Studies, University of British Columbia (Okanagan Campus), Canada, as well as an international digital media scholar and practitioner, primarily research interests in adopting extended realities and intelligence technologies for well-being and for social good. Dr. Wan’s research focuses on innovating artistic and socially motivated design through creative media by means of gamification in digital heritage preservation, museums archives and digital conservation; employing creative media for the socially disadvantaged by means of adopting extended realities and intelligence technologies for well-being.</p>
						
				</div>				
			</div>

			<div id="theabout" class="projectItem2">
				<div class="shrunkLeft">
                <h2>ABOUT</h2>
                <p>AI-enabled AR/VR-based exergames have the potential to enable a broader spectrum of users to participate in rehabilitative and fitness activities in immersive social environments that provide continual feedback to improve performance and incentivize continued usage. However, consumer grade AR/VR systems do not yet have the full capabilities needed to realize exergaming at scale. These challenges include, but are not limited to AI feedback algorithms that can run on untethered systems, long-term usage comfort due to system bulkiness, inability to simulate real-world attributes such as weight and resistance, novel exercise routine generation, and multi-user latency.</p>

                <p>Through <b>invited talks, demos, papers, and posters,</b> AIVR4Exergame will bring researchers and industry practitioners together to discuss these new emerging research challenges and technologies. Following topics are of interest.
                <ul>
						<li>Design of exergames to facilitate long-term continued usage</li>
						<li>Privacy and security and related topics for AI and AR/VR use in exergaming</li>
						<li>Ethical considerations for use of AI for AR/VR-based exergaming</li>
						<li>Design of AI algorithms that provide closed-loop feedback to enable continued usability</li>
						<li>Design of AI algorithms for assessing and correcting virtual interactions for safe usage</li>
						<li>Design of AI algorithms to generate novel exercise routines</li>
						<li>Simulating the real-world in AR/VR (e.g., weight, friction, resistance)</li>
						<li>AI techniques for movement tracking using smartphone sensors for smartphone-based AR/VR exergaming</li>
						<li>Incorporating haptics and biofeedback to ensure safe interactions in immersive AR/VR environments</li>
						<li>Effectiveness of AI-enabled AR/VR-based exergaming through results from case studies</li>
						<li>Emergent hardware platforms to enable broader uptake of AR/VR-based exergames</li>
						<li>Long term physical and psychological effects of exergaming in AR/VR</li>						
						<li>Co-located and remote social environments for AR/VR exergaming</li>
						<li>Designing rehabilitative AR/VR exergames for children, older adults, and individuals with disabilities</li>
						<li>AR/VR-based tele-rehab server platform to connect participants from remote locations</li>
                    </ul>
                </p>
				
				<p>The workshop will be held <b>in-person (with remote options)</b> at the Osaka University Toyonaka Campus, in Toyonaka, Osaka, Japan, and is co-located with <a href="https://aivr.science.uu.nl/2026/" target="_blank">IEEE AIxVR 2026</a>.</p>
                </div>                
            </div>
                     
            <div id="theorg" class="projectItem2">
                <div class="shrunkLeft">
                <p><h2>ORGANIZERS</h2>
                <div class="peopleTable">
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/nbanerjee.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="http://tars-home.github.io/">NATASHA BANERJEE</a><br/>Associate Professor<br/>Terascale All-sensing Research Studio (TARS)<br/>Wright State University<br/>
                        </div>
                    </div>
                    
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/sbanerjee.jpg"/>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="http://tars-home.github.io/">SEAN BANERJEE</a><br/>Associate Professor<br/>Terascale All-sensing Research Studio (TARS)<br/>Wright State University<br/>
                        </div>
                    </div>

					
                    
                                    
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/ashutosh.jpg"/>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="http://tars-home.github.io/">ASHUTOSH SHIVAKUMAR</a><br/>Assistant Professor<br/>Terascale All-sensing Research Studio (TARS)<br/>Wright State University<br/>
                        </div>
                    </div>
					
					
                </div>
				
                For questions, contact us as sean dot banerjee a wright d edu<br/><br/><br/><br/><br/>
				</div>
			</div>    
    
            <script type="text/javascript">
                $(".button").on("click", function(){
                    var path = $(this).attr("data-path");
                    var anchor = $("#" + path);
                    var position = anchor.position().top + $("#container").scrollTop();                
                    $("#container").animate({scrollTop: position});
                });
                $(".inlink").on("click", function(){
                    var path = $(this).attr("data-path");
                    var anchor = $("#" + path);
                    var position = anchor.position().top + $("#container").scrollTop();
                    $("#container").animate({scrollTop: position});
                });
                
                
                var interval;
                var userScroll = false;
                
                function mouseEvent(e) {
                    userScroll = true;
                }            
            </script> 
		</div>
    </BODY>
</HTML>

