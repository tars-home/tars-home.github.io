<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<HTML xmlns="http://www.w3.org/1999/xhtml">
    <HEAD>
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <TITLE>HUBEDA</TITLE>
        <LINK rel="StyleSheet" href="./webstyle.css" type="text/css" media="all">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
        <script src="jquery-3.2.1.js"></script>
    </HEAD>
    <BODY style="margin: 0px;">
        <div class="header">
            <div class="header-bar">
                <div class="navTable">
                    <div class="navRow" id="myNavRow">                    
                        <div style="display:table-cell;" class="button" data-path="theabout">&nbsp;&nbsp;ABOUT&nbsp;&nbsp;</div>&nbsp;&nbsp;
                        <div style="display:table-cell;" class="button" data-path="theinvited">&nbsp;&nbsp;INVITED&nbsp;SPEAKERS&nbsp;&nbsp;</div>&nbsp;&nbsp;                        
                        <div style="display:table-cell;" class="button" data-path="thedemos">&nbsp;&nbsp;DEMOS&nbsp;&nbsp;</div>&nbsp;&nbsp;                        
                        <div style="display:table-cell;" class="button" data-path="thepaper">&nbsp;&nbsp;CALL&nbsp;FOR&nbsp;PAPERS&nbsp;&nbsp;</div>&nbsp;&nbsp;
                        
                    </div>
                    <div class="navRow" id="myNavRow">                    
                        <div style="display:table-cell;" class="button" data-path="thetravel">&nbsp;&nbsp;TRAVEL&nbsp;GRANT&nbsp;&nbsp;</div>&nbsp;&nbsp;
                        <div style="display:table-cell;"  class="button" data-path="thedates">&nbsp;&nbsp;DATES&nbsp;&nbsp;</div>&nbsp;
                        <div style="display:table-cell;" class="button" data-path="theorg">&nbsp;&nbsp;ORGANIZERS&nbsp;&nbsp;</div>
                    </div>
                </div>
            </div>
        </div>
        
        
        <div id="container" class="content">
            <div id="thetop" class="topBackground backBanner">
                    <!--<img src = "./images/back.jpg"/>-->
            </div>
            <div style="background-color: #CCCCCC; z-index: 10; position: fixed; left: 10px; padding: 10px; border-radius: 10px;" class="button" data-path="thetop">
                Top
            </div>
            
            <div id="theabout" class="projectItem">
                <div class="shrunkLeft">
                <p><h1>HUBEDA</h1></p>

				<p><h2>Workshop on Human Behavior Data Acquisition for Human-Robot Interaction</h2></p>

                <p><b>Co-Located with IEEE RO-MAN 2024<br/>Workshop Date: August 30, 2024</b></p>
                <p><b><div class="inlink" data-path="thepaper">Call for Papers</div></b></p>
                
                <p>A vast number of advancements have been made in making robots engage in more natural human-robot interaction (HRI). To close the gap on enabling safe seamless human-aware HRI, collection of large data on human behavior, specially diverse multi-person interactions spanning large participant counts, is still an open challenge. Data on human behavior spans visual information on human movements, gestures, and interactions, spoken content, textual information, and physiological data such as heart rate, electromyography, and electrodermal activity.</p>

                <p>Through <b>invited talks, demos, papers, and posters,</b> HUBEDA addresses fundamental questions on the acquisition, analysis, and use of large-scale data on human behavior and interactions to enable data-informed HRI. Following topics are of interest.
                <ul>
                    <li>Datasets on single-person behavior and multi-person interaction for HRI</li>
                    <li>Multimodal setups integrating visual, audio, inertial, tactile, and physiological sensing for full-range capture</li>
                    <li>Augmented reality / virtual reality (AR/VR) approaches to scale up human subject data collection for HRI</li>
                    <li>AI, machine learning (ML), vision, and natural language processing (NLP) approaches to estimate parameters of interest for HRI from datasets on human behavior</li>
                    <li>Leveraging large vision and language models to decipher human activity, text, and spoken content</li>
                    <li>Robotic implementations driven using human behavior datasets</li>
                    <li>Robot learning from human behavior datasets and multi-person interactions</li>
                    <li>Applications involving multiple agents such as collaborative assembly, handover, repair</li>
                    <li>Ethical practices in data collection for single/multi-person behavior</li>
                    <li>Addressing challenges in reaching out to diverse population groups, e.g., children, older adults, and individuals with disabilities, to scale up data collection</li>
                </ul>
                </p>
                 
                <p>The workshop is supported through a generous donation from the <a href="https://delucafoundation.org/">De Luca Foundation</a>.</p>
                </div>
            </div>

            <div id="theinvited" class="projectItem2">
                <div class="shrunkLeft">
                <p><h2>INVITED SPEAKERS</h2>

                <div class="peopleTable">
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/aajoudani.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="https://www.iit.it/people-details/-/people/arash-ajoudani">ARASH AJOUDANI</a><br/>Director, HRII Laboratory<br/>Italian Institute of Technology<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/vnovak.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="https://researchdirectory.uc.edu/p/novakdn">VESNA NOVAK</a><br/>Associate Professor, Department of Electrical Engineering and Computer Science<br/>University of Cincinnati<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/eshort.jpeg"/>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="https://eshort.github.io/">ELAINE SHORT</a><br/>Assistant Professor, Department of Computer Science<br/>Tufts University<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/probinette.jpeg"></img>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="https://sites.uml.edu/paul-robinette/">PAUL ROBINETTE</a><br/>Assistant Professor, Department of Electrical and Computer Engineering<br/>University of Massachusetts Lowell<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/pbiswas.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="https://cambum.net/PB/">PRADIPTA BISWAS</a><br/>Associate Professor, Center for Product Design and Manufacturing<br/>Indian Institute of Science<br/>
                        </div>
                    </div>                    
                </div>
            </p>
            </div>

            <div id="thedemos" class="projectItem">
                <div class="shrunkLeft">
                    <p><h2>DEMOS</h2>
                <p>At HUBEDA, we will have <b>demos</b> from <a href="https://www.universal-robots.com/">Universal Robots</a> on current advances and from <a href="https://tars-home.github.io/">TARS</a> on integrating physiological sensing with robotic to enable HRI applications. Attendees will receive the opportunity to interact with robots from UR and TARS, and ask the presenters questions about the technology.

                <p><h3>DEMO PRESENTERS</h3></p>
                <div class="peopleTable">
                    
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/rmancilla.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            RAFAEL MANCILLA</a><br/>Business Development Manager<br/>Universal Robots<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/puetz.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            PAT UETZ</a><br/>Business Development Manager<br/>Advanced Technology Consultants<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/amegyeri.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            AVA MEGYERI<br/>Graduate Student, Department of Computer Science and Engineering<br/>Wright State University<br/>
                        </div>
                    </div>
                </div>
            </div>
            
            <div id="thepaper" class="projectItem2">
                <div class="shrunkLeft">
                <p><h2>CALL FOR PAPERS</h2>
                We invite authors to submit papers of up to 6 pages (including references) on the <span class="inlink" data-path="theabout">topics of interest</span>. Accepted papers will be published on the workshop webpage and on arXiv. Authors are also invited to submit extended abstracts of up to 4 pages (including references) to be presented at the workshop on early-phase work, late-breaking results, and demonstrations, to be presented at the workshop.  Authors of accepted papers will be invited to submit a full paper a special issue (to be determined) to enable publications associated with the workshop.</p>

                <p>The goal of the workshop is to bootstrap research on data-driven methods in HRI. A full working result on a robot, though encouraged, is not strictly necessary for acceptance. Rather, papers must demonstrate how their setup, methods, algorithms, and/or datasets provide human behavior data to HRI and/or robotics in general.</p>

                <p><b>Submission link:</b> <a target="_blank" href="https://easychair.org/my/conference?conf=hubeda2024">https://easychair.org/my/conference?conf=hubeda2024</a>

                    <p>Papers submissions should follow the template at <a target="_blank" href="https://www.ro-man2024.org/contributing/regularpapersubmission">https://www.ro-man2024.org/contributing/regularpapersubmission</a>.</p>
                </div>
            </div>
            <div id="thetravel" class="projectItem2">
                <div class="shrunkLeft">
                <p><h2>TRAVEL GRANT</h2>
                To encourage student participation, HUBEDA will be sponsoring <b>travel grants</b> for student attendees based on merit and need. Travel grants are competitive, and priority will be provided to presenters. We highly encourage students from underrepresented communities, including women, individuals with disabilities, and students from underrepresented minorities to apply. The link for the travel grant will be posted soon.</p>
                </div>
            </div>
            <div id="thedates" class="projectItem2">
                <div class="shrunkLeft">
                <p><h2>IMPORTANT DATES</h2>
                <ul>
                    <li>Paper Submission Deadline (Second Extension): <s>Jun 30, 2024, AOE</s> <s>Jul 15, 2024, AOE</s> <b>Jul 31, 2024, AOE</b></li>
                    <li>Notification of Paper Acceptance: Aug 3, 2024, AOE</li>
                    <li>Travel Grant Application Submission: Aug 5, 2024, AOE</li>
                    <li>Final Paper Submission: Aug 7, 2024, AOE</li>
                    <li>Travel Grant Notification: Aug 7, 2024, AOE</li>
                    <li>Workshop: Aug 30, 2024</li>
                </ul>
                </p>
                </div>
            </div>
            <div id="theorg" class="projectItem2">
                <div class="shrunkLeft">
                <p><h2>ORGANIZERS</h2>
                <div class="peopleTable">
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/nbanerjee.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="http://tars-home.github.io/">NATASHA BANERJEE</a><br/>Associate Professor<br/>Terascale All-sensing Research Studio (TARS)<br/>Wright State University<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/mkyrarini.jpg"></img>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="https://sites.google.com/view/mariakyrarini/home">MARIA KYRARINI</a><br/>Assistant Professor<br/>Human-Machine Interaction &amp; Innovation Lab (HMI2)<br/>Santa Clara University<br/>
                        </div>
                    </div>
                    <div class="peopleCell">
                        <div class="peopleContainer">
                            <img src="images/sbanerjee.jpg"/>
                        </div>
                        <div class="peopleBio">
                            <a target = "_blank" href="http://tars-home.github.io/">SEAN BANERJEE</a><br/>Associate Professor<br/>Terascale All-sensing Research Studio (TARS)<br/>Wright State University<br/>
                        </div>
                    </div>                    
                </div>
                For questions, contact us as hubeda2024 a gmail d com<br/><br/><br/><br/><br/>
            </div>
            
    
            <script type="text/javascript">
                $(".button").on("click", function(){
                    var path = $(this).attr("data-path");
                    var anchor = $("#" + path);
                    var position = anchor.position().top + $("#container").scrollTop();                
                    $("#container").animate({scrollTop: position});
                });
                $(".inlink").on("click", function(){
                    var path = $(this).attr("data-path");
                    var anchor = $("#" + path);
                    var position = anchor.position().top + $("#container").scrollTop();
                    $("#container").animate({scrollTop: position});
                });
                
                
                var interval;
                var userScroll = false;
                
                function mouseEvent(e) {
                    userScroll = true;
                }            
            </script>
        </div>
    </BODY>
</HTML>

